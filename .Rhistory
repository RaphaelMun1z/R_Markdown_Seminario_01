# Verificar estrutura
glimpse(dados)
# Remover linhas com salários ausentes
dados <- dados %>% filter(!is.na(Salary))
# Separar faixa salarial em mínimo e máximo (em mil dólares)
dados <- dados %>%
mutate(
salario_limpo = str_extract(Salary, "\\$\\d+K\\s-\\s\\$\\d+K"),
salario_min = as.numeric(str_extract(salario_limpo, "\\d+")) * 1000,
salario_max = as.numeric(str_extract(salario_limpo, "(?<=-\\s\\$)\\d+")) * 1000,
salario_medio = (salario_min + salario_max) / 2
)
dados %>%
group_by(`Job Title`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
arrange(desc(Media_Salarial)) %>%
head(10) %>%
ggplot(aes(x = reorder(`Job Title`, Media_Salarial), y = Media_Salarial)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Top 10 Cargos com Maior Salário Médio", x = "", y = "Salário Médio (USD)")
ggplot(dados, aes(x = `Company Score`, y = salario_medio)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Salário Médio vs Avaliação da Empresa",
x = "Avaliação da Empresa",
y = "Salário Médio (USD)")
# Análise de salários por localização
dados %>%
group_by('Location') %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
arrange(desc(Media_Salarial)) %>%
head(10) %>%
ggplot(aes(x = reorder('Location', Media_Salarial), y = Media_Salarial)) +
geom_col(fill = "lightgreen") +
coord_flip() +
labs(title = "Top 10 Localizações com Maior Salário Médio", x = "", y = "Salário Médio (USD)")
```{r}
knitr::opts_chunk$set(echo = TRUE)
# Carregar pacotes necessários
library(dplyr)
library(readr)
library(ggplot2)
library(stringr)
# Leitura do arquivo CSV
dados <- read_csv("C:/Users/rapha/Desktop/Estatística/SoftwareEngineerSalaries.csv")
# Verificar estrutura
glimpse(dados)
# Remover linhas com salários ausentes
dados <- dados %>% filter(!is.na(Salary))
# Separar faixa salarial em mínimo e máximo (em mil dólares)
dados <- dados %>%
mutate(
salario_limpo = str_extract(Salary, "\\$\\d+K\\s-\\s\\$\\d+K"),
salario_min = as.numeric(str_extract(salario_limpo, "\\d+")) * 1000,
salario_max = as.numeric(str_extract(salario_limpo, "(?<=-\\s\\$)\\d+")) * 1000,
salario_medio = (salario_min + salario_max) / 2
)
dados %>%
group_by(`Job Title`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
arrange(desc(Media_Salarial)) %>%
head(10) %>%
ggplot(aes(x = reorder(`Job Title`, Media_Salarial), y = Media_Salarial)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Top 10 Cargos com Maior Salário Médio", x = "", y = "Salário Médio (USD)")
ggplot(dados, aes(x = `Company Score`, y = salario_medio)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Salário Médio vs Avaliação da Empresa",
x = "Avaliação da Empresa",
y = "Salário Médio (USD)")
# Análise de salários por localização
dados %>%
group_by(`Location`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
arrange(desc(Media_Salarial)) %>%
head(10) %>%
ggplot(aes(x = reorder(`Location`, Media_Salarial), y = Media_Salarial)) +
geom_col(fill = "lightgreen") +
coord_flip() +
labs(title = "Top 10 Localizações com Maior Salário Médio", x = "", y = "Salário Médio (USD)")
```{r}
knitr::opts_chunk$set(echo = TRUE)
# Carregar pacotes necessários
library(dplyr)
library(readr)
library(ggplot2)
library(stringr)
# Leitura do arquivo CSV
dados <- read_csv("C:/Users/rapha/Desktop/Estatística/SoftwareEngineerSalaries.csv")
# Verificar estrutura
glimpse(dados)
# Remover linhas com salários ausentes
dados <- dados %>% filter(!is.na(Salary))
# Separar faixa salarial em mínimo e máximo (em mil dólares)
dados <- dados %>%
mutate(
salario_limpo = str_extract(Salary, "\\$\\d+K\\s-\\s\\$\\d+K"),
salario_min = as.numeric(str_extract(salario_limpo, "\\d+")) * 1000,
salario_max = as.numeric(str_extract(salario_limpo, "(?<=-\\s\\$)\\d+")) * 1000,
salario_medio = (salario_min + salario_max) / 2
)
dados %>%
group_by(`Job Title`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
arrange(desc(Media_Salarial)) %>%
head(10) %>%
ggplot(aes(x = reorder(`Job Title`, Media_Salarial), y = Media_Salarial)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Top 10 Cargos com Maior Salário Médio", x = "", y = "Salário Médio (USD)")
ggplot(dados, aes(x = `Company Score`, y = salario_medio)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Salário Médio vs Avaliação da Empresa",
x = "Avaliação da Empresa",
y = "Salário Médio (USD)")
# Análise de salários por localização
dados %>%
group_by(`Location`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
arrange(desc(Media_Salarial)) %>%
head(10) %>%
ggplot(aes(x = reorder(`Location`, Media_Salarial), y = Media_Salarial)) +
geom_col(fill = "lightgreen") +
coord_flip() +
labs(title = "Top 10 Localizações com Maior Salário Médio", x = "", y = "Salário Médio (USD)")
# Análise de Pontuação de Empresas
dados %>%
group_by(`Company Score`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
ggplot(aes(x = `Company Score`, y = Media_Salarial)) +
geom_line(color = "purple") +
geom_point() +
labs(title = "Salário Médio por Pontuação da Empresa",
x = "Pontuação da Empresa",
y = "Salário Médio (USD)")
knitr::opts_chunk$set(echo = TRUE)
# Carregar pacotes necessários
library(dplyr)
library(readr)
library(ggplot2)
library(stringr)
# Leitura do arquivo CSV
dados <- read_csv("C:/Users/rapha/Desktop/Estatística/SoftwareEngineerSalaries.csv")
# Verificar estrutura
glimpse(dados)
# Remover linhas com salários ausentes
dados <- dados %>% filter(!is.na(Salary))
# Separar faixa salarial em mínimo e máximo (em mil dólares)
dados <- dados %>%
mutate(
salario_limpo = str_extract(Salary, "\\$\\d+K\\s-\\s\\$\\d+K"),
salario_min = as.numeric(str_extract(salario_limpo, "\\d+")) * 1000,
salario_max = as.numeric(str_extract(salario_limpo, "(?<=-\\s\\$)\\d+")) * 1000,
salario_medio = (salario_min + salario_max) / 2
)
dados %>%
group_by(`Job Title`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
arrange(desc(Media_Salarial)) %>%
head(10) %>%
ggplot(aes(x = reorder(`Job Title`, Media_Salarial), y = Media_Salarial)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Top 10 Cargos com Maior Salário Médio", x = "", y = "Salário Médio (USD)")
ggplot(dados, aes(x = `Company Score`, y = salario_medio)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Salário Médio vs Avaliação da Empresa",
x = "Avaliação da Empresa",
y = "Salário Médio (USD)")
# Análise de salários por localização
dados %>%
group_by(`Location`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
arrange(desc(Media_Salarial)) %>%
head(10) %>%
ggplot(aes(x = reorder(`Location`, Media_Salarial), y = Media_Salarial)) +
geom_col(fill = "lightgreen") +
coord_flip() +
labs(title = "Top 10 Localizações com Maior Salário Médio", x = "", y = "Salário Médio (USD)")
# Análise de Pontuação de Empresas
dados %>%
group_by(`Company Score`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
ggplot(aes(x = `Company Score`, y = Media_Salarial)) +
geom_line(color = "purple") +
geom_point() +
labs(title = "Salário Médio por Pontuação da Empresa",
x = "Pontuação da Empresa",
y = "Salário Médio (USD)")
# Relação Localização e Salário
dados %>%
group_by(`Location`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
ggplot(aes(x = reorder(`Location`, Media_Salarial), y = Media_Salarial)) +
geom_col(fill = "orange") +
coord_flip() +
labs(title = "Salário Médio por Localização", x = "", y = "Salário Médio (USD)")
knitr::opts_chunk$set(echo = TRUE)
# Carregar pacotes necessários
library(dplyr)
library(readr)
library(ggplot2)
library(stringr)
# Leitura do arquivo CSV
dados <- read_csv("C:/Users/rapha/Desktop/Estatística/SoftwareEngineerSalaries.csv")
# Verificar estrutura
glimpse(dados)
# Remover linhas com salários ausentes
dados <- dados %>% filter(!is.na(Salary))
# Separar faixa salarial em mínimo e máximo (em mil dólares)
dados <- dados %>%
mutate(
salario_limpo = str_extract(Salary, "\\$\\d+K\\s-\\s\\$\\d+K"),
salario_min = as.numeric(str_extract(salario_limpo, "\\d+")) * 1000,
salario_max = as.numeric(str_extract(salario_limpo, "(?<=-\\s\\$)\\d+")) * 1000,
salario_medio = (salario_min + salario_max) / 2
)
dados %>%
group_by(`Job Title`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
arrange(desc(Media_Salarial)) %>%
head(10) %>%
ggplot(aes(x = reorder(`Job Title`, Media_Salarial), y = Media_Salarial)) +
geom_col(fill = "steelblue") +
coord_flip() +
labs(title = "Top 10 Cargos com Maior Salário Médio", x = "", y = "Salário Médio (USD)")
ggplot(dados, aes(x = `Company Score`, y = salario_medio)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Salário Médio vs Avaliação da Empresa",
x = "Avaliação da Empresa",
y = "Salário Médio (USD)")
# Análise de salários por localização
dados %>%
group_by(`Location`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
arrange(desc(Media_Salarial)) %>%
head(10) %>%
ggplot(aes(x = reorder(`Location`, Media_Salarial), y = Media_Salarial)) +
geom_col(fill = "lightgreen") +
coord_flip() +
labs(title = "Top 10 Localizações com Maior Salário Médio", x = "", y = "Salário Médio (USD)")
# Análise de Pontuação de Empresas
dados %>%
group_by(`Company Score`) %>%
summarise(Media_Salarial = mean(salario_medio, na.rm = TRUE)) %>%
ggplot(aes(x = `Company Score`, y = Media_Salarial)) +
geom_line(color = "purple") +
geom_point() +
labs(title = "Salário Médio por Pontuação da Empresa",
x = "Pontuação da Empresa",
y = "Salário Médio (USD)")
# Relação Localização e Top Salário
dados %>%
group_by(`Location`) %>%
summarise(Max_Salario = max(salario_medio, na.rm = TRUE)) %>%
arrange(desc(Max_Salario)) %>%
head(10) %>%
ggplot(aes(x = reorder(`Location`, Max_Salario), y = Max_Salario)) +
geom_col(fill = "orange") +
coord_flip() +
labs(title = "Top 10 Localizações com Maior Salário Máximo", x = "", y = "Salário Máximo (USD)")
---
title: "Análise de Salários de Engenheiros de Software"
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
### Carrega as bibliotecas
```{r}
### Carrega o dataset
```{r}
# Leitura do arquivo CSV
setwd("C:/Users/rapha/Desktop/Estatística")
dados<-read.csv("melb_data.csv",dec=".",sep=",",header =T)
# Leitura do arquivo CSV
setwd("C:/Users/rapha/Desktop/Estatística/dataset")
setwd("C:/Users/rapha/Desktop/estatistica/dataset")
dados<-read.csv("melb_data.csv",dec=".",sep=",",header =T)
dados<-read.csv("melb_data.csv",dec=".",sep=",",header =T)
# Leitura do arquivo CSV
setwd("C:/Users/rapha/Desktop/estatistica/dataset")
dados<-read.csv("melb_data.csv",dec=".",sep=",",header =T)
dados<-read.csv("melb_data.csv",dec=".",sep=",",header =T)
setwd("C:/Users/rapha/Desktop/estatistica/dataset")
dados<-read.csv("melb_data.csv",dec=".",sep=",",header =T)
dados <- read_csv("C:/Users/rapha/Desktop/estatistica/dataset/melb_data.csv")
dados<-read.csv("melb_data.csv",dec=".",sep=",",header =T)
# Leitura do arquivo CSV
setwd("C:/Users/rapha/Desktop/estatistica/dataset")
dados<-read.csv("melb_data.csv",dec=".",sep=",",header =T)
dados<-read.csv("dataset.csv",dec=".",sep=",",header =T)
dados<-read.csv("dataset.csv")
getwd()
setwd("C:/Users/rapha/Desktop/estatistica/dataset")
getwd()
dados<-read.csv("dataset.csv",dec=".",sep=",",header =T)
dados<-read.csv("dataset/dataset.csv",dec=".",sep=",",header =T)
# Leitura do arquivo CSV
setwd("C:/Users/rapha/Desktop/estatistica/dataset/")
# Leitura do arquivo CSV
setwd("C:/Users/rapha/Desktop/estatistica/dataset/")
getwd()
# Leitura do arquivo CSV
setwd("C:/Users/rapha/Desktop/estatistica/dataset")
getwd()
dados<-read.csv("dataset/dataset.csv",dec=".",sep=",",header =T)
# Verificar estrutura
glimpse(dados)
# Carregar pacotes necessários
library(dplyr)
# Carregar pacotes necessários
library(dplyr)
library(readr)
# Carregar pacotes necessários
library(dplyr)
library(readr)
library(ggplot2)
library(stringr)
# Carregar pacotes necessários
library(dplyr)
library(readr)
library(ggplot2)
library(stringr)
### Carrega o dataset
```{r}
### Características do dataset
```{r}
# Verificar estrutura
glimpse(dados)
# Filtrar colunas
# Selecionar as colunas 'nome' e 'idade'
dados_selecionados <- dados[ , c("Rooms", "Price")]
# Ver o resultado
print(dados_selecionados)
# Filtrar colunas
# Selecionar as colunas 'nome' e 'idade'
dados_selecionados <- dados[ , c("Rooms", "Price", "Postcode", "Bathroom", "Car", "Landsize", "BuildingArea", "Lattitude")]
# Ver o resultado
print(dados_selecionados)
# Filtrar colunas
# Selecionar as colunas 'nome' e 'idade'
dados_selecionados <- dados[ , c("Rooms", "Price", "Postcode", "Bathroom", "Car", "Landsize", "BuildingArea", "Lattitude", "SellerG")]
# Ver o resultado
print(dados_selecionados)
# Filtrar colunas
# Selecionar as colunas 'nome' e 'idade'
dados_selecionados <- dados[ , c("Rooms", "Price", "Postcode", "Bathroom", "Car", "Landsize", "BuildingArea", "Lattitude", "SellerG", "Method")]
# Ver o resultado
print(dados_selecionados)
# Ver o resultado
print(dados_selecionados)
# Filtrar colunas
# Selecionar as colunas 'nome' e 'idade'
dados_selecionados <- dados[ , c("Rooms", "Price", "Postcode", "Bathroom", "Car", "Landsize", "BuildingArea", "Lattitude", "SellerG", "Method", "Type")]
# Ver o resultado
print(dados_selecionados)
knitr::opts_chunk$set(echo = TRUE)
# Carregar pacotes necessários
library(dplyr)
library(readr)
library(ggplot2)
library(stringr)
# Leitura do arquivo CSV
setwd("C:/Users/rapha/Desktop/estatistica/dataset")
getwd()
dados<-read.csv("dataset/dataset.csv",dec=".",sep=",",header =T)
knitr::opts_chunk$set(echo = TRUE)
# Carregar pacotes necessários
library(dplyr)
library(readr)
library(ggplot2)
library(stringr)
# Leitura do arquivo CSV
setwd("C:/Users/rapha/Desktop/estatistica/dataset")
getwd()
dados<-read.csv("dataset.csv",dec=".",sep=",",header =T)
# Verificar estrutura
glimpse(dados)
# Filtrar colunas
# Selecionar as colunas desejadas
dados_selecionados <- dados[ , c("Rooms", "Price", "Postcode", "Bathroom", "Car", "Landsize", "BuildingArea", "Lattitude", "SellerG", "Method", "Type")]
# Ver o resultado
print(dados_selecionados)
# Carregar pacotes necessários
library(dplyr)    # Para manipulação de dados
library(ggplot2)  # Para visualização gráfica (opcional, mas útil)
# Dica: Se você está no RStudio, pode usar File -> Import Dataset -> From Text (base)
# e navegar até o arquivo para carregá-lo e ele mostrará o código para você.
# Visualizar as primeiras linhas e a estrutura dos dados
head(dados)
glimpse(dados)
# --- 1. Estatística Descritiva Básica ---
# A função summary() oferece um bom resumo estatístico para todas as colunas
summary(dados)
# Para variáveis qualitativas, podemos usar table()
table(dados$Suburb)
table(dados$Regionname)
table(dados$Type)
table(dados$Method)
# Para variáveis quantitativas, podemos usar histogramas para ver a distribuição
hist(dados$Price, main = "Distribuição dos Preços", xlab = "Preço")
hist(dados$Rooms, main = "Distribuição do Número de Quartos", xlab = "Quartos")
# Scatter plot para visualizar a relação entre duas variáveis quantitativas
# Ex: Preço vs. Tamanho do terreno (Landsize)
ggplot(dados, aes(x = Landsize, y = Price)) +
geom_point(alpha = 0.5) +
labs(title = "Preço vs. Tamanho do Terreno", x = "Tamanho do Terreno", y = "Preço") +
theme_minimal()
# --- 2. Medidas de Posição ---
# Vamos focar em algumas colunas quantitativas como 'Price' (Preço) e 'Landsize' (Tamanho do Terreno)
# Média Aritmética
media_preco <- mean(dados$Price, na.rm = TRUE) # na.rm = TRUE para remover valores NA (missing values)
media_quartos <- mean(dados$Rooms, na.rm = TRUE)
media_terreno <- mean(dados$Landsize, na.rm = TRUE)
cat("Média do Preço:", media_preco, "\n")
cat("Média do Número de Quartos:", media_quartos, "\n")
cat("Média do Tamanho do Terreno:", media_terreno, "\n")
# Mediana
mediana_preco <- median(dados$Price, na.rm = TRUE)
mediana_quartos <- median(dados$Rooms, na.rm = TRUE)
mediana_terreno <- median(dados$Landsize, na.rm = TRUE)
cat("Mediana do Preço:", mediana_preco, "\n")
cat("Mediana do Número de Quartos:", mediana_quartos, "\n")
cat("Mediana do Tamanho do Terreno:", mediana_terreno, "\n")
# Moda
# O R base não tem uma função de 'moda' direta. Precisamos criar uma ou usar pacotes.
# Exemplo de função simples para a moda:
get_mode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
# Para colunas com muitos valores únicos, a moda pode não ser muito informativa.
# Vamos aplicar a 'Rooms' (Quartos) que deve ter valores mais repetidos.
moda_quartos <- get_mode(dados$Rooms)
cat("Moda do Número de Quartos:", moda_quartos, "\n")
# Para colunas categóricas, a 'moda' é a categoria mais frequente, que pode ser vista com table()
moda_tipo_imovel <- names(sort(table(dados$Type), decreasing = TRUE))[1]
cat("Moda do Tipo de Imóvel:", moda_tipo_imovel, "\n")
# --- 3. Medidas de Dispersão ---
# Amplitude Total
# Max - Min. A função range() retorna o mínimo e o máximo.
amplitude_preco <- max(dados$Price, na.rm = TRUE) - min(dados$Price, na.rm = TRUE)
amplitude_terreno <- max(dados$Landsize, na.rm = TRUE) - min(dados$Landsize, na.rm = TRUE)
cat("Amplitude Total do Preço:", amplitude_preco, "\n")
cat("Amplitude Total do Tamanho do Terreno:", amplitude_terreno, "\n")
# Desvio Médio Absoluto (MAD)
# O R tem a função mad() que calcula a Mediana do Desvio Absoluto, não o desvio médio absoluto.
# Para o desvio médio absoluto (Average Absolute Deviation - AAD), podemos calcular manualmente.
# AAD = sum(|x_i - mean(x)|) / n
desvio_medio_abs_preco <- mean(abs(dados$Price - mean(dados$Price, na.rm = TRUE)), na.rm = TRUE)
desvio_medio_abs_terreno <- mean(abs(dados$Landsize - mean(dados$Landsize, na.rm = TRUE)), na.rm = TRUE)
cat("Desvio Médio Absoluto do Preço:", desvio_medio_abs_preco, "\n")
cat("Desvio Médio Absoluto do Tamanho do Terreno:", desvio_medio_abs_terreno, "\n")
# Variância
variancia_preco <- var(dados$Price, na.rm = TRUE)
variancia_quartos <- var(dados$Rooms, na.rm = TRUE)
variancia_terreno <- var(dados$Landsize, na.rm = TRUE)
cat("Variância do Preço:", variancia_preco, "\n")
cat("Variância do Número de Quartos:", variancia_quartos, "\n")
cat("Variância do Tamanho do Terreno:", variancia_terreno, "\n")
# Desvio-Padrão
desvio_padrao_preco <- sd(dados$Price, na.rm = TRUE)
desvio_padrao_quartos <- sd(dados$Rooms, na.rm = TRUE)
desvio_padrao_terreno <- sd(dados$Landsize, na.rm = TRUE)
cat("Desvio Padrão do Preço:", desvio_padrao_preco, "\n")
cat("Desvio Padrão do Número de Quartos:", desvio_padrao_quartos, "\n")
cat("Desvio Padrão do Tamanho do Terreno:", desvio_padrao_terreno, "\n")
# Coeficiente de Variação (CV)
# CV = (Desvio Padrão / Média) * 100
cv_preco <- (desvio_padrao_preco / media_preco) * 100
cv_terreno <- (desvio_padrao_terreno / media_terreno) * 100
cat("Coeficiente de Variação do Preço:", cv_preco, "%\n")
cat("Coeficiente de Variação do Tamanho do Terreno:", cv_terreno, "%\n")
# Interpretando o CV: O preço tem uma variabilidade relativa muito maior que o tamanho do terreno.
# Quantis: Quartil, Decil e Percentil
# Função quantile() é usada para isso.
# Quartis (0%, 25%, 50%, 75%, 100%)
quartis_preco <- quantile(dados$Price, probs = c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE)
cat("Quartis do Preço:\n")
print(quartis_preco)
# Decis (10%, 20%, ..., 90%)
decis_terreno <- quantile(dados$Landsize, probs = seq(0.1, 0.9, by = 0.1), na.rm = TRUE)
cat("Decis do Tamanho do Terreno:\n")
print(decis_terreno)
# Percentis (Ex: 5º, 95º percentil)
percentil_5_preco <- quantile(dados$Price, probs = 0.05, na.rm = TRUE)
percentil_95_preco <- quantile(dados$Price, probs = 0.95, na.rm = TRUE)
cat("5º Percentil do Preço:", percentil_5_preco, "\n")
cat("95º Percentil do Preço:", percentil_95_preco, "\n")
# --- Medidas de Posição e Dispersão no Excel ---
# Embora a apostila mencione o Excel, o R é a ferramenta para as operações solicitadas.
# No Excel, essas medidas são calculadas usando funções como:
# - Média: =MÉDIA(intervalo)
# - Mediana: =MED(intervalo)
# - Moda: =MODO.ÚNICO(intervalo) ou =MODO.MULT(intervalo)
# - Amplitude Total: =MÁXIMO(intervalo) - MÍNIMO(intervalo)
# - Desvio Padrão (amostral): =DESVPAD.A(intervalo)
# - Variância (amostral): =VAR.A(intervalo)
# - Coeficiente de Variação: (DESVPAD.A(intervalo) / MÉDIA(intervalo)) * 100
# - Quartis: =QUARTIL.EXC(intervalo, 1), =QUARTIL.EXC(intervalo, 2), etc.
# - Percentis: =PERCENTIL.EXC(intervalo, k)
# Para exportar os resultados do R para o Excel, você pode salvar os data frames ou tabelas geradas:
# write.csv(summary(dados), "resumo_estatistico.csv", row.names = FALSE)
# write.csv(as.data.frame(table(dados$Regionname)), "frequencia_regiao.csv", row.names = FALSE)
# Para exportar os resultados do R para o Excel, você pode salvar os data frames ou tabelas geradas:
# write.csv(summary(dados), "resumo_estatistico.csv", row.names = FALSE)
# write.csv(as.data.frame(table(dados$Regionname)), "frequencia_regiao.csv", row.names = FALSE)
